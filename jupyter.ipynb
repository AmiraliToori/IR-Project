{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import GUI\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer  # type: ignore\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# function to create the excel files\n",
    "def create_excel_dataframe(input , name, columns, index):\n",
    "    df = pd.DataFrame(input, columns = columns, index = index) # Create a pandas dataframe\n",
    "    df.to_excel(name) # Create an excel file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/glados/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the Stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def convert_to_list(doc) -> list:\n",
    "    doc = re.sub(r\"[^\\w\\s]\", \" \", doc)\n",
    "    doc = doc.split()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "dictionary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/glados/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "def is_meaningful(word) -> bool:\n",
    "    \n",
    "    if wn.synsets(word):\n",
    "        return True\n",
    "    else: \n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_dictionary(doc, dictionary) -> list:\n",
    "    for word_index, word in enumerate(doc):\n",
    "        \n",
    "        word = word.lower()\n",
    "        \n",
    "        if word.isalnum() and word not in stop_words and is_meaningful(word) and len(word) > 1:\n",
    "            \n",
    "            stem_word = stemmer.stem(word)\n",
    "            doc[word_index] = stem_word\n",
    "            \n",
    "            if stem_word not in dictionary:\n",
    "                dictionary.append(stem_word)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def join_document(doc) -> str:\n",
    "    doc = ' '.join(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_document(document) -> str:\n",
    "    \n",
    "    document = convert_to_list(document)\n",
    "    \n",
    "    document = create_dictionary(document, dictionary)\n",
    "    \n",
    "    document = join_document(document)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "raw_document = GUI.select_file() # Select File GUI implementation\n",
    "\n",
    "raw_dataset = raw_document # the raw dataset that read from the one file\n",
    "\n",
    "raw_dataset = raw_dataset.split(\".I\") # split the docs by index\n",
    "\n",
    "raw_dataset.remove(raw_dataset[0]) # remove the empty first index\n",
    "\n",
    "doc_index = 0\n",
    "    \n",
    "\n",
    "# write each index in 'raw_dataset'\n",
    "for doc in raw_dataset:\n",
    "    doc_index += 1\n",
    "    doc_path = \"/home/glados/Documents/AmirAli Toori/Lessons/Python/IR-Project/docs\" + \"/doc\" + str(doc_index) + \".txt\"\n",
    "    doc = process_document(doc)\n",
    "    \n",
    "    \n",
    "    with open(doc_path, \"w\") as document: # write each index into the separated doc\n",
    "        document.write(doc)\n",
    "\n",
    "doc_index = 0\n",
    "\n",
    "for doc in raw_dataset:\n",
    "    doc_index += 1\n",
    "    doc_path = \"/home/glados/Documents/AmirAli Toori/Lessons/Python/IR-Project/Original docs\" + \"/docs\" + str(doc_index) + \".txt\"\n",
    "    \n",
    "    \n",
    "    with open(doc_path, \"w\") as document: # write each index into the separated doc\n",
    "        document.write(doc)\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Extract Documents\", f\"There have been {doc_index} documents are extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>investig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aerodynam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slipstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>hopkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>aeolotrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>intuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>recover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>ob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words\n",
       "0     experiment\n",
       "1       investig\n",
       "2      aerodynam\n",
       "3           wing\n",
       "4     slipstream\n",
       "...          ...\n",
       "3859      hopkin\n",
       "3860   aeolotrop\n",
       "3861      intuit\n",
       "3862     recover\n",
       "3863          ob\n",
       "\n",
       "[3864 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dictionary, columns=[\"Words\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"dictionary.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "term_doc_matrix = np.zeros((len(dictionary), doc_index))\n",
    "tf_array = np.zeros((len(dictionary), doc_index))\n",
    "idf_array = np.zeros((len(dictionary), 1))\n",
    "tf_idf_array = np.zeros((len(dictionary), doc_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def calculate_term_frequency(doc, dictionary, doc_no):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            frequency = doc.count(word)\n",
    "            row = dictionary.index(word)\n",
    "            column = doc_no - 1\n",
    "            tf_array[row, column] += frequency\n",
    "\n",
    "\n",
    "def calculate_inverse_document_frequency(doc, dictionary):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            row = dictionary.index(word)\n",
    "            idf_array[row, 0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "doc_names_list = []\n",
    "for num in range(1, doc_index + 1):\n",
    "    doc_path = \"/home/glados/Documents/AmirAli Toori/Lessons/Python/IR-Project/docs\" + \"/doc\" + str(num) + \".txt\"\n",
    "    doc_names_list.append(\"doc\" + str(num) + \".txt\")\n",
    "    with open(doc_path, \"r\") as file:\n",
    "        doc = file.read()\n",
    "        calculate_term_frequency(doc, dictionary, num)\n",
    "        calculate_inverse_document_frequency(doc, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# calculating tf array\n",
    "row, column = np.shape(tf_array)\n",
    "for r in range(row):\n",
    "    for c in range(column):\n",
    "        if tf_array[r, c] > 0:\n",
    "            extracted_element = tf_array[r, c]\n",
    "            tf_array[r, c] = 1 + np.log10(extracted_element)\n",
    "        else:\n",
    "            tf_array[r, c] = 0\n",
    "            \n",
    "GUI.custom_window(\"700x35\", \"Complete!\", \"The calculation of Term Frequency is have been successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "count_of_documents = column\n",
    "row, column = np.shape(idf_array)\n",
    "\n",
    "\n",
    "# calculating idf array\n",
    "for r in range(row):\n",
    "    if idf_array[r, 0] > 0:\n",
    "        extracted_element = idf_array[r, 0]\n",
    "        idf_array[r, 0] = np.log10(count_of_documents / extracted_element)\n",
    "    else:\n",
    "        idf_array[r, 0] = 0\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Complete!\", \"The calculation of Inverse Document Frequency is have been successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# multiply peer to peer each row of tf-array in idf-array\n",
    "row, column = np.shape(tf_idf_array)\n",
    "r, c = 0, 0\n",
    "while r < row:\n",
    "        tf_idf_array[r, c]= tf_array[r, c] * idf_array[r, 0]\n",
    "        c += 1\n",
    "        if c == column:\n",
    "            r += 1\n",
    "            c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tf_dataframe = create_excel_dataframe(tf_array, \"tf_excel.xlsx\", doc_names_list, dictionary)\n",
    "\n",
    "idf_dataframe = create_excel_dataframe(idf_array, \"idf_excel.xlsx\", [\"IDF\"], dictionary)\n",
    "\n",
    "tf_idf_dataframe = create_excel_dataframe(tf_idf_array, \"tf_idf_excel.xlsx\", doc_names_list, dictionary)\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Excel File\", \"Creating the Excel file is DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1.txt</th>\n",
       "      <th>doc2.txt</th>\n",
       "      <th>doc3.txt</th>\n",
       "      <th>doc4.txt</th>\n",
       "      <th>doc5.txt</th>\n",
       "      <th>doc6.txt</th>\n",
       "      <th>doc7.txt</th>\n",
       "      <th>doc8.txt</th>\n",
       "      <th>doc9.txt</th>\n",
       "      <th>doc10.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>doc1391.txt</th>\n",
       "      <th>doc1392.txt</th>\n",
       "      <th>doc1393.txt</th>\n",
       "      <th>doc1394.txt</th>\n",
       "      <th>doc1395.txt</th>\n",
       "      <th>doc1396.txt</th>\n",
       "      <th>doc1397.txt</th>\n",
       "      <th>doc1398.txt</th>\n",
       "      <th>doc1399.txt</th>\n",
       "      <th>doc1400.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>1.301030</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>1.301030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>1.301030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.954243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
       "experiment  1.477121   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "investig    1.301030   1.00000       0.0   0.00000       0.0   0.00000   \n",
       "aerodynam   1.301030   0.00000       0.0   0.00000       1.0   0.00000   \n",
       "wing        1.602060   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "slipstream  1.778151   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "hopkin      0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "aeolotrop   0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "intuit      0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "recover     0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "ob          1.000000   1.60206       0.0   1.30103       0.0   1.30103   \n",
       "\n",
       "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
       "experiment       0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "investig         1.0   1.00000  1.477121        0.0  ...          0.0   \n",
       "aerodynam        0.0   0.00000  0.000000        0.0  ...          1.0   \n",
       "wing             0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "slipstream       0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "...              ...       ...       ...        ...  ...          ...   \n",
       "hopkin           0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "aeolotrop        0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "intuit           0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "recover          0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "ob               0.0   1.30103  1.301030        0.0  ...          1.0   \n",
       "\n",
       "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
       "experiment     1.000000          0.0     0.000000          0.0          1.0   \n",
       "investig       0.000000          1.0     0.000000          1.0          0.0   \n",
       "aerodynam      0.000000          0.0     0.000000          0.0          0.0   \n",
       "wing           0.000000          0.0     0.000000          0.0          0.0   \n",
       "slipstream     0.000000          0.0     0.000000          0.0          0.0   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "hopkin         1.000000          0.0     0.000000          0.0          0.0   \n",
       "aeolotrop      1.000000          0.0     0.000000          0.0          0.0   \n",
       "intuit         1.000000          0.0     0.000000          0.0          0.0   \n",
       "recover        0.000000          0.0     1.000000          0.0          0.0   \n",
       "ob             1.954243          0.0     1.477121          0.0          1.0   \n",
       "\n",
       "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
       "experiment          1.0      0.00000          0.0          0.0  \n",
       "investig            0.0      0.00000          0.0          1.0  \n",
       "aerodynam           0.0      0.00000          0.0          0.0  \n",
       "wing                0.0      0.00000          0.0          0.0  \n",
       "slipstream          0.0      0.00000          0.0          0.0  \n",
       "...                 ...          ...          ...          ...  \n",
       "hopkin              0.0      0.00000          0.0          0.0  \n",
       "aeolotrop           0.0      0.00000          0.0          0.0  \n",
       "intuit              0.0      0.00000          0.0          0.0  \n",
       "recover             0.0      0.00000          0.0          0.0  \n",
       "ob                  1.0      1.30103          0.0          1.0  \n",
       "\n",
       "[3864 rows x 1400 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.615928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>0.586221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>0.876615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>0.788193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>1.970037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>1.714764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>0.241954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IDF\n",
       "experiment  0.615928\n",
       "investig    0.586221\n",
       "aerodynam   0.876615\n",
       "wing        0.788193\n",
       "slipstream  1.970037\n",
       "...              ...\n",
       "hopkin      3.146128\n",
       "aeolotrop   3.146128\n",
       "intuit      3.146128\n",
       "recover     1.714764\n",
       "ob          0.241954\n",
       "\n",
       "[3864 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1.txt</th>\n",
       "      <th>doc2.txt</th>\n",
       "      <th>doc3.txt</th>\n",
       "      <th>doc4.txt</th>\n",
       "      <th>doc5.txt</th>\n",
       "      <th>doc6.txt</th>\n",
       "      <th>doc7.txt</th>\n",
       "      <th>doc8.txt</th>\n",
       "      <th>doc9.txt</th>\n",
       "      <th>doc10.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>doc1391.txt</th>\n",
       "      <th>doc1392.txt</th>\n",
       "      <th>doc1393.txt</th>\n",
       "      <th>doc1394.txt</th>\n",
       "      <th>doc1395.txt</th>\n",
       "      <th>doc1396.txt</th>\n",
       "      <th>doc1397.txt</th>\n",
       "      <th>doc1398.txt</th>\n",
       "      <th>doc1399.txt</th>\n",
       "      <th>doc1400.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.909801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>0.762692</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.865920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>1.140503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>1.262733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>3.503023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.387624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.472836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
       "experiment  0.909801  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "investig    0.762692  0.586221       0.0  0.000000  0.000000  0.000000   \n",
       "aerodynam   1.140503  0.000000       0.0  0.000000  0.876615  0.000000   \n",
       "wing        1.262733  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "slipstream  3.503023  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "hopkin      0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "aeolotrop   0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "intuit      0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "recover     0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "ob          0.241954  0.387624       0.0  0.314789  0.000000  0.314789   \n",
       "\n",
       "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
       "experiment  0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "investig    0.586221  0.586221  0.865920        0.0  ...     0.000000   \n",
       "aerodynam   0.000000  0.000000  0.000000        0.0  ...     0.876615   \n",
       "wing        0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "slipstream  0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "...              ...       ...       ...        ...  ...          ...   \n",
       "hopkin      0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "aeolotrop   0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "intuit      0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "recover     0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "ob          0.000000  0.314789  0.314789        0.0  ...     0.241954   \n",
       "\n",
       "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
       "experiment     0.615928     0.000000     0.000000     0.000000     0.615928   \n",
       "investig       0.000000     0.586221     0.000000     0.586221     0.000000   \n",
       "aerodynam      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "wing           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "slipstream     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "hopkin         3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "aeolotrop      3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "intuit         3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "recover        0.000000     0.000000     1.714764     0.000000     0.000000   \n",
       "ob             0.472836     0.000000     0.357395     0.000000     0.241954   \n",
       "\n",
       "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
       "experiment     0.615928     0.000000          0.0     0.000000  \n",
       "investig       0.000000     0.000000          0.0     0.586221  \n",
       "aerodynam      0.000000     0.000000          0.0     0.000000  \n",
       "wing           0.000000     0.000000          0.0     0.000000  \n",
       "slipstream     0.000000     0.000000          0.0     0.000000  \n",
       "...                 ...          ...          ...          ...  \n",
       "hopkin         0.000000     0.000000          0.0     0.000000  \n",
       "aeolotrop      0.000000     0.000000          0.0     0.000000  \n",
       "intuit         0.000000     0.000000          0.0     0.000000  \n",
       "recover        0.000000     0.000000          0.0     0.000000  \n",
       "ob             0.241954     0.314789          0.0     0.241954  \n",
       "\n",
       "[3864 rows x 1400 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query = input(\"Please enter what you want to search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query_lower = query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query_words_list = query_lower.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire', 'kept', 'alive', 'love', 'love', 'gods', 'love']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the stop words\n",
    "for word in query_words_list:\n",
    "    if word in stop_words or not is_meaningful(word):\n",
    "        query_words_list.remove(word)  \n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire kept alive love love gods love'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_list = \" \".join(query_words_list)\n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire kept alive love love gods love'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_list = re.sub(r\"[^\\w\\s]\",\" \", query_words_list)\n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire kept alive love love gods love'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "string = [query_words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2773501 , 0.2773501 , 0.2773501 , 0.2773501 , 0.83205029]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    " \n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(string)\n",
    "\n",
    "query_tfidf = result.toarray()\n",
    "query_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def change_shape(document):\n",
    "    document = np.array(document)\n",
    "    row = np.shape(document)\n",
    "    row = row[0]\n",
    "    document.shape = (1, row)\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m row, column \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(tf_idf_array)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, column):\n\u001b[0;32m----> 5\u001b[0m     doc_column \u001b[38;5;241m=\u001b[39m \u001b[43mtf_idf_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m     doc_column \u001b[38;5;241m=\u001b[39m change_shape(doc_column)\n\u001b[1;32m      9\u001b[0m     nominator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(query_tfidf, doc_column)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "row, column = np.shape(tf_idf_array)\n",
    "\n",
    "for number in range(1, column):\n",
    "    \n",
    "    doc_column = tf_idf_dataframe([\"doc\"+ str(number) +\".txt\"]).tolist()\n",
    "    \n",
    "    doc_column = change_shape(doc_column)\n",
    "    \n",
    "    nominator = np.dot(query_tfidf, doc_column)\n",
    "    \n",
    "    doc_column_norm = np.linalg.norm(doc_column)\n",
    "    query_tfidf = np.linalg.norm(query_tfidf)\n",
    "    \n",
    "    denominator = doc_column_norm * query_tfidf\n",
    "    \n",
    "    cosine_theta = nominator / denominator\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
