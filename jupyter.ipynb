{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import GUI\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer  # type: ignore\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import re\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create dataframe and excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# function to create the excel files\n",
    "def create_excel_dataframe(input , name, columns, index):\n",
    "    df = pd.DataFrame(input, columns = columns, index = index) # Create a pandas dataframe\n",
    "    df.to_excel(name) # Create an excel file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the **stopwords** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/glados/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the punctuation from the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def convert_to_list(doc) -> list:\n",
    "    doc = re.sub(r\"[^\\w\\s]\", \" \", doc)\n",
    "    doc = doc.split()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "dictionary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download wordnet and create a method to check that the word have meaning or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/glados/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "def is_meaningful(word) -> bool:\n",
    "    \n",
    "    if wn.synsets(word):\n",
    "        return True\n",
    "    else: \n",
    "        return False    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_dictionary(doc, dictionary) -> list:\n",
    "    for word_index, word in enumerate(doc):\n",
    "        \n",
    "        word = word.lower()\n",
    "        \n",
    "        if word.isalnum() and word not in stop_words and is_meaningful(word) and len(word) > 1:\n",
    "            \n",
    "            stem_word = stemmer.stem(word)\n",
    "            doc[word_index] = stem_word\n",
    "            \n",
    "            if stem_word not in dictionary:\n",
    "                dictionary.append(stem_word)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to join the words together with one space distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def join_document(doc) -> str:\n",
    "    doc = ' '.join(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods which contain the methods to process the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_document(document) -> str:\n",
    "    \n",
    "    document = convert_to_list(document)\n",
    "    \n",
    "    document = create_dictionary(document, dictionary)\n",
    "    \n",
    "    document = join_document(document)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a dataset to extract, then extracted the results in the two type of documents, the processed docs goes to **docs** directory, and the original docs saved to **Original docs** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "raw_document = GUI.select_file() # Select File GUI implementation\n",
    "\n",
    "raw_dataset = raw_document # the raw dataset that read from the one file\n",
    "\n",
    "raw_dataset = raw_dataset.split(\".I\") # split the docs by index\n",
    "\n",
    "raw_dataset.remove(raw_dataset[0]) # remove the empty first index\n",
    "\n",
    "doc_index = 0\n",
    "    \n",
    "\n",
    "# write each index in 'raw_dataset'\n",
    "for doc in raw_dataset:\n",
    "    doc_index += 1\n",
    "    doc_path = \"./docs\" + \"/doc\" + str(doc_index) + \".txt\"\n",
    "    doc = process_document(doc)\n",
    "    \n",
    "    \n",
    "    with open(doc_path, \"w\") as document: # write each index into the separated doc\n",
    "        document.write(doc)\n",
    "\n",
    "doc_index = 0\n",
    "\n",
    "for doc in raw_dataset:\n",
    "    doc_index += 1\n",
    "    doc_path = \"./Original docs\" + \"/docs\" + str(doc_index) + \".txt\"\n",
    "    \n",
    "    \n",
    "    with open(doc_path, \"w\") as document: # write each index into the separated doc\n",
    "        document.write(doc)\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Extract Documents\", f\"There have been {doc_index} documents are extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>investig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aerodynam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slipstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>hopkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>aeolotrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>intuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>recover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>ob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words\n",
       "0     experiment\n",
       "1       investig\n",
       "2      aerodynam\n",
       "3           wing\n",
       "4     slipstream\n",
       "...          ...\n",
       "3859      hopkin\n",
       "3860   aeolotrop\n",
       "3861      intuit\n",
       "3862     recover\n",
       "3863          ob\n",
       "\n",
       "[3864 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dictionary, columns=[\"Words\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"dictionary.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized the numpy arrays for TF, IDF, TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "term_doc_matrix = np.zeros((len(dictionary), doc_index))\n",
    "tf_array = np.zeros((len(dictionary), doc_index))\n",
    "idf_array = np.zeros((len(dictionary), 1))\n",
    "tf_idf_array = np.zeros((len(dictionary), doc_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to calculate the TF, DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def calculate_term_frequency(doc, dictionary, doc_no):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            frequency = doc.count(word)\n",
    "            row = dictionary.index(word)\n",
    "            column = doc_no - 1\n",
    "            tf_array[row, column] += frequency\n",
    "\n",
    "\n",
    "def calculate_document_frequency(doc, dictionary):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            row = dictionary.index(word)\n",
    "            idf_array[row, 0] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads the Documents one by one to calculate the TF, DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "doc_names_list = []\n",
    "for num in range(1, doc_index + 1):\n",
    "    doc_path = \"./docs\" + \"/doc\" + str(num) + \".txt\"\n",
    "    doc_names_list.append(\"doc\" + str(num) + \".txt\")\n",
    "    with open(doc_path, \"r\") as file:\n",
    "        doc = file.read()\n",
    "        calculate_term_frequency(doc, dictionary, num)\n",
    "        calculate_document_frequency(doc, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Term Frequency **(TF)** for each word in each document:\n",
    "\n",
    "$$\n",
    "TF_{(w,d)}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\text{ if } \\;\\;\\; tf_{(w,d)} > 0  \\;\\;\\;\\;\\;\\;\\;\\; 1 + \\log(tf_{(w,d)})\\\\\n",
    "\\text{otherwise} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; 0 \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "row, column = np.shape(tf_array)\n",
    "\n",
    "for r in range(row):\n",
    "    for c in range(column):\n",
    "        if tf_array[r, c] > 0:\n",
    "            extracted_element = tf_array[r, c]\n",
    "            tf_array[r, c] = 1 + np.log10(extracted_element)\n",
    "        else:\n",
    "            tf_array[r, c] = 0\n",
    "\n",
    "            \n",
    "GUI.custom_window(\"700x35\", \"Complete!\", \"The calculation of Term Frequency is have been successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Inverse Document Frequency **(IDF)** for each word:\n",
    "\n",
    "$$\n",
    "IDF_{(w)} = \\log(\\frac{N}{df_{w}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "count_of_documents = column\n",
    "row, column = np.shape(idf_array)\n",
    "\n",
    "for r in range(row):\n",
    "    if idf_array[r, 0] > 0:\n",
    "        extracted_element = idf_array[r, 0]\n",
    "        idf_array[r, 0] = np.log10(count_of_documents / extracted_element)\n",
    "    else:\n",
    "        idf_array[r, 0] = 0\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Complete!\", \"The calculation of Inverse Document Frequency is have been successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the TF-IDF by multiplying peer to peer each row of TF array into IDF array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "row, column = np.shape(tf_idf_array)\n",
    "r, c = 0, 0\n",
    "while r < row:\n",
    "        tf_idf_array[r, c]= tf_array[r, c] * idf_array[r, 0]\n",
    "        c += 1\n",
    "        if c == column:\n",
    "            r += 1\n",
    "            c = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the TF, IDF, TF-IDF dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tf_dataframe = create_excel_dataframe(tf_array, \"tf_excel.xlsx\", doc_names_list, dictionary)\n",
    "\n",
    "idf_dataframe = create_excel_dataframe(idf_array, \"idf_excel.xlsx\", [\"IDF\"], dictionary)\n",
    "\n",
    "tf_idf_dataframe = create_excel_dataframe(tf_idf_array, \"tf_idf_excel.xlsx\", doc_names_list, dictionary)\n",
    "\n",
    "GUI.custom_window(\"700x35\", \"Excel File\", \"Creating the Excel file is DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1.txt</th>\n",
       "      <th>doc2.txt</th>\n",
       "      <th>doc3.txt</th>\n",
       "      <th>doc4.txt</th>\n",
       "      <th>doc5.txt</th>\n",
       "      <th>doc6.txt</th>\n",
       "      <th>doc7.txt</th>\n",
       "      <th>doc8.txt</th>\n",
       "      <th>doc9.txt</th>\n",
       "      <th>doc10.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>doc1391.txt</th>\n",
       "      <th>doc1392.txt</th>\n",
       "      <th>doc1393.txt</th>\n",
       "      <th>doc1394.txt</th>\n",
       "      <th>doc1395.txt</th>\n",
       "      <th>doc1396.txt</th>\n",
       "      <th>doc1397.txt</th>\n",
       "      <th>doc1398.txt</th>\n",
       "      <th>doc1399.txt</th>\n",
       "      <th>doc1400.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>1.301030</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>1.301030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>1.301030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.954243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
       "experiment  1.477121   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "investig    1.301030   1.00000       0.0   0.00000       0.0   0.00000   \n",
       "aerodynam   1.301030   0.00000       0.0   0.00000       1.0   0.00000   \n",
       "wing        1.602060   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "slipstream  1.778151   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "hopkin      0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "aeolotrop   0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "intuit      0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "recover     0.000000   0.00000       0.0   0.00000       0.0   0.00000   \n",
       "ob          1.000000   1.60206       0.0   1.30103       0.0   1.30103   \n",
       "\n",
       "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
       "experiment       0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "investig         1.0   1.00000  1.477121        0.0  ...          0.0   \n",
       "aerodynam        0.0   0.00000  0.000000        0.0  ...          1.0   \n",
       "wing             0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "slipstream       0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "...              ...       ...       ...        ...  ...          ...   \n",
       "hopkin           0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "aeolotrop        0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "intuit           0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "recover          0.0   0.00000  0.000000        0.0  ...          0.0   \n",
       "ob               0.0   1.30103  1.301030        0.0  ...          1.0   \n",
       "\n",
       "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
       "experiment     1.000000          0.0     0.000000          0.0          1.0   \n",
       "investig       0.000000          1.0     0.000000          1.0          0.0   \n",
       "aerodynam      0.000000          0.0     0.000000          0.0          0.0   \n",
       "wing           0.000000          0.0     0.000000          0.0          0.0   \n",
       "slipstream     0.000000          0.0     0.000000          0.0          0.0   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "hopkin         1.000000          0.0     0.000000          0.0          0.0   \n",
       "aeolotrop      1.000000          0.0     0.000000          0.0          0.0   \n",
       "intuit         1.000000          0.0     0.000000          0.0          0.0   \n",
       "recover        0.000000          0.0     1.000000          0.0          0.0   \n",
       "ob             1.954243          0.0     1.477121          0.0          1.0   \n",
       "\n",
       "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
       "experiment          1.0      0.00000          0.0          0.0  \n",
       "investig            0.0      0.00000          0.0          1.0  \n",
       "aerodynam           0.0      0.00000          0.0          0.0  \n",
       "wing                0.0      0.00000          0.0          0.0  \n",
       "slipstream          0.0      0.00000          0.0          0.0  \n",
       "...                 ...          ...          ...          ...  \n",
       "hopkin              0.0      0.00000          0.0          0.0  \n",
       "aeolotrop           0.0      0.00000          0.0          0.0  \n",
       "intuit              0.0      0.00000          0.0          0.0  \n",
       "recover             0.0      0.00000          0.0          0.0  \n",
       "ob                  1.0      1.30103          0.0          1.0  \n",
       "\n",
       "[3864 rows x 1400 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.615928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>0.586221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>0.876615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>0.788193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>1.970037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>3.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>1.714764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>0.241954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IDF\n",
       "experiment  0.615928\n",
       "investig    0.586221\n",
       "aerodynam   0.876615\n",
       "wing        0.788193\n",
       "slipstream  1.970037\n",
       "...              ...\n",
       "hopkin      3.146128\n",
       "aeolotrop   3.146128\n",
       "intuit      3.146128\n",
       "recover     1.714764\n",
       "ob          0.241954\n",
       "\n",
       "[3864 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1.txt</th>\n",
       "      <th>doc2.txt</th>\n",
       "      <th>doc3.txt</th>\n",
       "      <th>doc4.txt</th>\n",
       "      <th>doc5.txt</th>\n",
       "      <th>doc6.txt</th>\n",
       "      <th>doc7.txt</th>\n",
       "      <th>doc8.txt</th>\n",
       "      <th>doc9.txt</th>\n",
       "      <th>doc10.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>doc1391.txt</th>\n",
       "      <th>doc1392.txt</th>\n",
       "      <th>doc1393.txt</th>\n",
       "      <th>doc1394.txt</th>\n",
       "      <th>doc1395.txt</th>\n",
       "      <th>doc1396.txt</th>\n",
       "      <th>doc1397.txt</th>\n",
       "      <th>doc1398.txt</th>\n",
       "      <th>doc1399.txt</th>\n",
       "      <th>doc1400.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.909801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.615928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investig</th>\n",
       "      <td>0.762692</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.865920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerodynam</th>\n",
       "      <td>1.140503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wing</th>\n",
       "      <td>1.262733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slipstream</th>\n",
       "      <td>3.503023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeolotrop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ob</th>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.387624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.472836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3864 rows × 1400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
       "experiment  0.909801  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "investig    0.762692  0.586221       0.0  0.000000  0.000000  0.000000   \n",
       "aerodynam   1.140503  0.000000       0.0  0.000000  0.876615  0.000000   \n",
       "wing        1.262733  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "slipstream  3.503023  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "hopkin      0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "aeolotrop   0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "intuit      0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "recover     0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "ob          0.241954  0.387624       0.0  0.314789  0.000000  0.314789   \n",
       "\n",
       "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
       "experiment  0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "investig    0.586221  0.586221  0.865920        0.0  ...     0.000000   \n",
       "aerodynam   0.000000  0.000000  0.000000        0.0  ...     0.876615   \n",
       "wing        0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "slipstream  0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "...              ...       ...       ...        ...  ...          ...   \n",
       "hopkin      0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "aeolotrop   0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "intuit      0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "recover     0.000000  0.000000  0.000000        0.0  ...     0.000000   \n",
       "ob          0.000000  0.314789  0.314789        0.0  ...     0.241954   \n",
       "\n",
       "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
       "experiment     0.615928     0.000000     0.000000     0.000000     0.615928   \n",
       "investig       0.000000     0.586221     0.000000     0.586221     0.000000   \n",
       "aerodynam      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "wing           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "slipstream     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "hopkin         3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "aeolotrop      3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "intuit         3.146128     0.000000     0.000000     0.000000     0.000000   \n",
       "recover        0.000000     0.000000     1.714764     0.000000     0.000000   \n",
       "ob             0.472836     0.000000     0.357395     0.000000     0.241954   \n",
       "\n",
       "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
       "experiment     0.615928     0.000000          0.0     0.000000  \n",
       "investig       0.000000     0.000000          0.0     0.586221  \n",
       "aerodynam      0.000000     0.000000          0.0     0.000000  \n",
       "wing           0.000000     0.000000          0.0     0.000000  \n",
       "slipstream     0.000000     0.000000          0.0     0.000000  \n",
       "...                 ...          ...          ...          ...  \n",
       "hopkin         0.000000     0.000000          0.0     0.000000  \n",
       "aeolotrop      0.000000     0.000000          0.0     0.000000  \n",
       "intuit         0.000000     0.000000          0.0     0.000000  \n",
       "recover        0.000000     0.000000          0.0     0.000000  \n",
       "ob             0.241954     0.314789          0.0     0.241954  \n",
       "\n",
       "[3864 rows x 1400 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query = input(\"Please enter what you want to search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query_lower = query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "query_words_list = query_lower.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh',\n",
       " 'hell',\n",
       " 'night',\n",
       " 'city',\n",
       " 'wake',\n",
       " 'fuck',\n",
       " 'samurai',\n",
       " 'have',\n",
       " 'city',\n",
       " 'burn']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the stop words\n",
    "for word in query_words_list:\n",
    "    if word in stop_words or not is_meaningful(word):\n",
    "        query_words_list.remove(word)  \n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh',\n",
       " 'hell',\n",
       " 'night',\n",
       " 'citi',\n",
       " 'wake',\n",
       " 'fuck',\n",
       " 'samurai',\n",
       " 'have',\n",
       " 'citi',\n",
       " 'burn']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [stemmer.stem(word) for word in query_words_list]\n",
    "query_words = set(temp) \n",
    "query_words_list = temp\n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh hell night citi wake fuck samurai have citi burn'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_list = \" \".join(query_words_list)\n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh hell night citi wake fuck samurai have citi burn'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_list = re.sub(r\"[^\\w\\s]\",\" \", query_words_list)\n",
    "query_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "string = [query_words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'burn', 'citi', 'fuck', 'have', 'hell', 'night', 'oh', 'samurai', 'wake'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the **TF-IDF** of **Query**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28867513, 0.57735027, 0.28867513, 0.28867513, 0.28867513,\n",
       "       0.28867513, 0.28867513, 0.28867513, 0.28867513])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    " \n",
    "\n",
    "result = tfidf.fit_transform(string)\n",
    "\n",
    "query_tfidf = np.squeeze(result.toarray())\n",
    "query_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'hell', 'night', 'citi', 'wake', 'fuck', 'samurai', 'have', 'burn']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words = list(tfidf.vocabulary_.keys())\n",
    "query_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the values of the words in query which is not present in dictionary documents to Zero(0).\n",
    "for corresponding the query words and the dictionary, we obtain the indexes of the words in the dictionary, to for later change the rows of the tf_idf array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'night': 2908, 'citi': 3355, 'wake': 546, 'burn': 1521}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words_in_dictionary = {}\n",
    "\n",
    "for index, word in enumerate(query_words):\n",
    "    \n",
    "    if word not in dictionary:\n",
    "        query_tfidf[index] = 0\n",
    "    else:\n",
    "        query_words_in_dictionary.update({word : dictionary.index(word)})\n",
    "   \n",
    "      \n",
    "query_words_in_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.28867513, 0.28867513, 0.28867513,\n",
       "       0.        , 0.        , 0.        , 0.28867513])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pad 0 to query_tfidf to make it equal to the tf-idf of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, column = np.shape(tf_idf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3864"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tfidf = np.pad(query_tfidf, (0, row - len(query_tfidf) + 1), 'constant', constant_values = (0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move the values to the Corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for count, value in enumerate(query_tfidf):\n",
    "    if count < len(query_words):\n",
    "        if value > 0:\n",
    "            if query_words[count] != dictionary.index(query_words[count]):\n",
    "                dest_index = dictionary.index(query_words[count])\n",
    "                query_tfidf[dest_index] = value\n",
    "                query_tfidf[count] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3864,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(query_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3864,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tf_idf_dataframe[\"doc1.txt\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the **Cosine** similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cosine_values = []\n",
    "cosine_docs = []\n",
    "\n",
    "\n",
    "for number in range(1, column + 1):\n",
    "    \n",
    "    doc_name = \"doc\"+ str(number) +\".txt\"\n",
    "    doc_column = tf_idf_dataframe[doc_name].tolist()\n",
    "    \n",
    "    nominator = np.dot(query_tfidf, doc_column)\n",
    "    \n",
    "    doc_column_norm = np.linalg.norm(doc_column)\n",
    "    query_tfidf_norm = np.linalg.norm(query_tfidf)\n",
    "    \n",
    "    denominator = doc_column_norm * query_tfidf_norm\n",
    "    \n",
    "    cosine_theta = nominator / denominator\n",
    "    if cosine_theta != 0:\n",
    "        cosine_values.append(cosine_theta)\n",
    "        cosine_docs.append(doc_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank the **Cosine** Similarity:\n",
    "Create a dictionary based on the *cosine_docs* and *cosine_values*, get the **items** from the created dictionary; and set the **key** argument equal to the value of the item; for the descending order, set the reverse argument to *True*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc1141.txt', 0.1393532065631248),\n",
       " ('doc1368.txt', 0.1308034769776183),\n",
       " ('doc621.txt', 0.1307060595428954),\n",
       " ('doc619.txt', 0.12806356552261228),\n",
       " ('doc1152.txt', 0.12641130345722604),\n",
       " ('doc154.txt', 0.12095343866999612),\n",
       " ('doc480.txt', 0.11978030130690938),\n",
       " ('doc979.txt', 0.11521314570680773),\n",
       " ('doc691.txt', 0.10789233146055996),\n",
       " ('doc1196.txt', 0.10512351070754462),\n",
       " ('doc446.txt', 0.10226948051965148),\n",
       " ('doc527.txt', 0.09498685425916992),\n",
       " ('doc409.txt', 0.09380464687746644),\n",
       " ('doc1080.txt', 0.09347627215069507),\n",
       " ('doc282.txt', 0.09296509163086875),\n",
       " ('doc121.txt', 0.08704986395167301),\n",
       " ('doc1183.txt', 0.08679012876250579),\n",
       " ('doc289.txt', 0.08506502643891949),\n",
       " ('doc907.txt', 0.08325558437234795),\n",
       " ('doc126.txt', 0.0818121685735506),\n",
       " ('doc695.txt', 0.08163024421184224),\n",
       " ('doc103.txt', 0.08162972944624305),\n",
       " ('doc721.txt', 0.08030291418129155),\n",
       " ('doc1184.txt', 0.07955235363275141),\n",
       " ('doc563.txt', 0.07829026775104976),\n",
       " ('doc622.txt', 0.07785301640893755),\n",
       " ('doc536.txt', 0.07742764576181045),\n",
       " ('doc253.txt', 0.07612691567026282),\n",
       " ('doc374.txt', 0.07242946693435935),\n",
       " ('doc433.txt', 0.07043495978810725),\n",
       " ('doc97.txt', 0.0703437214713164),\n",
       " ('doc976.txt', 0.06989083758892314),\n",
       " ('doc17.txt', 0.06824314188297931),\n",
       " ('doc1371.txt', 0.0670389871331958),\n",
       " ('doc186.txt', 0.06685398542514132),\n",
       " ('doc449.txt', 0.0668156726515329),\n",
       " ('doc927.txt', 0.06608401095447872),\n",
       " ('doc148.txt', 0.06509017019314481),\n",
       " ('doc138.txt', 0.06390888255204692),\n",
       " ('doc530.txt', 0.06378260778924634),\n",
       " ('doc943.txt', 0.06311397787762234),\n",
       " ('doc714.txt', 0.06269020108436615),\n",
       " ('doc960.txt', 0.06252588242252977),\n",
       " ('doc672.txt', 0.06121604952097225),\n",
       " ('doc1268.txt', 0.058246417855018044),\n",
       " ('doc558.txt', 0.057150669083739024),\n",
       " ('doc1040.txt', 0.054046917700575486),\n",
       " ('doc311.txt', 0.05291142281234341),\n",
       " ('doc278.txt', 0.052878558080425776),\n",
       " ('doc89.txt', 0.052690093628335495),\n",
       " ('doc375.txt', 0.05169475275347951),\n",
       " ('doc1329.txt', 0.051328028750722135),\n",
       " ('doc363.txt', 0.05064409189943381),\n",
       " ('doc520.txt', 0.04690855410430663),\n",
       " ('doc152.txt', 0.04467376608991029),\n",
       " ('doc85.txt', 0.04426099995252335),\n",
       " ('doc344.txt', 0.04318829401665775),\n",
       " ('doc799.txt', 0.04207886832562597),\n",
       " ('doc1277.txt', 0.03917955694583427)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_rank = sorted(dict(zip(cosine_docs, cosine_values)).items(), key = lambda x: x[1], reverse = True)\n",
    "cosine_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe and excel file from the Cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([doc[1] for doc in cosine_rank], index = [doc[0] for doc in cosine_rank], columns = ['cosine'])\n",
    "df.to_excel(\"cosine_similarity.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
